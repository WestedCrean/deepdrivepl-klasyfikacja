{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPLKO Moduł 4 - praca domowa - Quickdraw 10 class - regularyzacja\n",
    "\n",
    "Twoim zadaniem w tym module będzie przygotowanie własnego modelu sieci neuronowej korzystając z regularyzacji.\n",
    "\n",
    "Lista rzeczy które musi spełnić Twój model:\n",
    "- [x] działać na wybranych przez Ciebie 10 klasach (bazuj na kodzie z modułu 3)\n",
    "- [ ] liczba parametrów pomiędzy 100'000 a 200'000\n",
    "- [ ] wykorzystane przynajmniej 2 sposoby walki z regularyzacją\n",
    "- [ ] mieć wykonane co najmniej 4 zmiany w celu poprawy wyniku; zachowaj wszystkie iteracje (modyfikując model możesz dodać opcje w funkji, bądź skopiować klasę/funkcję, tak by było widać kolejne architektury)\n",
    "- [ ] opisz co chcesz sprawdzić w kolejnych eksperymentach (np. sprawdzę czy Dropout pomaga i z jaką wartością drop ratio najbardziej)\n",
    "- [ ] uzyskiwać lepsze `validation accuracy` niż w przypadku pierwszego modelu z poprzedniego modułu (im więcej punktów procentowych różnicy tym lepiej)\n",
    "\n",
    "Zwizualizuj proszę:\n",
    "- [ ] historie treningów (wystarczy Val acc, ale train acc czy lossy też mogą być)\n",
    "- [ ] zależność: liczba parametrów - val acc\n",
    "\n",
    "Możesz (czyli opcjonalne rzeczy):\n",
    "- pracować na zmniejszonym zbiorze, by dobrać wartość parametrów\n",
    "- np. zastosować dropout, pooling i early stopping\n",
    "- zastosować TF2 - Keras / PyTorcha czy PL (Pytorch Lightning)\n",
    "- dodać LR scheduler do swojego treningu (i sprawdzić czy to poprawiło wynik)\n",
    "- zwizualizować dodatkowo:\n",
    "  - confussion matrix\n",
    "  - błędne przypadki\n",
    "\n",
    "Warto:\n",
    "- zmieniać 1 parametr między eksperymentami (szczególnie trudne gdy się już nabierze wyczucia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane        <class 'numpy.ndarray'>\n",
      "banana          <class 'numpy.ndarray'>\n",
      "cookie          <class 'numpy.ndarray'>\n",
      "diamond         <class 'numpy.ndarray'>\n",
      "dog             <class 'numpy.ndarray'>\n",
      "hot air balloon <class 'numpy.ndarray'>\n",
      "knife           <class 'numpy.ndarray'>\n",
      "parachute       <class 'numpy.ndarray'>\n",
      "scissors        <class 'numpy.ndarray'>\n",
      "wine glass      <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_names = [\"airplane\", \"banana\", \"cookie\", \"diamond\", \"dog\", \"hot air balloon\", \"knife\" ,\"parachute\", \"scissors\", \"wine glass\"]\n",
    "\n",
    "# wczytanie danych\n",
    "\n",
    "data_folder = \"../data/quickdraw/\"\n",
    "\n",
    "for name in class_names:\n",
    "    url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/%s.npy'%name\n",
    "    file_name = data_folder + url.split('/')[-1].split('?')[0]\n",
    "\n",
    "    url = url.replace(' ','%20')\n",
    "\n",
    "    if not os.path.isfile(file_name):\n",
    "        print(url, '==>', file_name)\n",
    "        urllib.request.urlretrieve(url, file_name)\n",
    "\n",
    "data = []\n",
    "for name in class_names:\n",
    "    file_name = data_folder + name + '.npy'\n",
    "    data.append(np.load(file_name, fix_imports=True, allow_pickle=True))\n",
    "    print('%-15s'%name,type(data[-1]))\n",
    "\n",
    "X = np.concatenate(data).reshape(-1,28,28,1)\n",
    "y = np.concatenate([np.full(d.shape[0], i) for i, d in enumerate(data)])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=12, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "from torchmetrics.functional.classification.accuracy import accuracy\n",
    "\n",
    "class QuickDrawCNN_PL(pl.LightningModule):\n",
    "    def __init__(self, X_train,y_train,X_val,y_val, batch_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.X_train = torch.FloatTensor(X_train).permute(0, 3, 1, 2)\n",
    "        self.X_val = torch.FloatTensor(X_val).permute(0, 3, 1, 2)\n",
    "        self.y_train = torch.LongTensor(y_train)\n",
    "        self.y_val = torch.LongTensor(y_val)\n",
    "        self.train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        self.val_dataset = TensorDataset(self.X_val, self.y_val)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        ####################\n",
    "        ### Don't chagne ###\n",
    "        assert type(self.X_train)==torch.Tensor\n",
    "        assert self.X_train.shape==torch.Size([len(X_train), 1, 28, 28])\n",
    "        assert self.X_train.dtype==torch.float32, \"Typ X_train niepoprawny\"\n",
    "\n",
    "        assert type(self.y_train)==torch.Tensor\n",
    "        assert self.y_train.shape==torch.Size([len(X_train)])\n",
    "        assert self.y_train.dtype==torch.int64, \"Typ y_train niepoprawny\"\n",
    "\n",
    "        assert type(self.X_val)==torch.Tensor\n",
    "        assert self.X_val.shape==torch.Size([len(X_val), 1, 28, 28])\n",
    "        assert self.X_val.dtype==torch.float32, \"Typ X_val niepoprawny\"\n",
    "\n",
    "        assert type(self.y_val)==torch.Tensor\n",
    "        assert self.y_val.shape==torch.Size([len(y_val)])\n",
    "        assert self.y_val.dtype==torch.int64, \"Typ y_val niepoprawny\"\n",
    "        ### Don't chagne ###\n",
    "        ####################\n",
    "\n",
    "\n",
    "        self.num_classes = 10\n",
    "        self.dims = (1, 28, 28)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(channels, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            #nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            #nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Conv2d(64, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 32),\n",
    "            nn.Linear(32, self.num_classes), \n",
    "        )\n",
    "\n",
    "        ####################\n",
    "        ### Don't chagne ###\n",
    "        assert any(['Conv2d' in str(_) for _ in self.model]), \"Zastosuj przynajmniej jedną warstwę Conv2d\"\n",
    "        assert len([_ for _ in self.model if 'Conv2d' in str(_)])==len([_ for _ in self.model if 'ReLU' in str(_)]), \"Po każdej warstwie Conv2d zastosuj funkcję aktywacji ReLU\"\n",
    "        ### Don't chagne ###\n",
    "        ####################\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy(preds, y, task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "        # Calling self.log will surface up scalars for you in TensorBoard\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=16)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuickDrawCNN_PL(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=256, out_features=32, bias=True)\n",
      "    (11): Linear(in_features=32, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters: 175082\n"
     ]
    }
   ],
   "source": [
    "# check model summary \n",
    "model = QuickDrawCNN_PL(X_train,y_train,X_val,y_val, batch_size=32)\n",
    "print(model)\n",
    "\n",
    "# check number of parameters\n",
    "num_of_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('Number of parameters:', num_of_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_of_params > 100_000, \"Za mało parametrów\"\n",
    "assert num_of_params < 200_000, \"Za dużo parametrów\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wiktor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\fabric\\connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 175 K \n",
      "-------------------------------------\n",
      "175 K     Trainable params\n",
      "0         Non-trainable params\n",
      "175 K     Total params\n",
      "0.700     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2433/2433 [00:48<00:00, 49.93it/s, v_num=8, val_loss=0.222, val_acc=0.933]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2433/2433 [00:48<00:00, 49.92it/s, v_num=8, val_loss=0.222, val_acc=0.933]\n"
     ]
    }
   ],
   "source": [
    "# You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti') that has Tensor Cores. \n",
    "# To properly utilize them, you should set \n",
    "# `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "model = QuickDrawCNN_PL(X_train,y_train,X_val,y_val, 128*4)\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"modul_3\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10, \n",
    "    precision=16, \n",
    "    accelerator=\"gpu\",\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-593ab71a2a86593\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-593ab71a2a86593\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wyślij rozwiązanie\n",
    "Możesz skorzystać z jednego z poniższych sposobów:\n",
    "**mailem na specjalny adres** ze strony pracy domowej w panelu programu prześlij jedno z poniższych:\n",
    "- notebooka (jeżeli plik ma mniej niż np. 10MB)\n",
    "- notebooka w zipie\n",
    "- link do Colaba (udostępniony)\n",
    "- link do pliku przez GDrive/Dropboxa/WeTransfer/...\n",
    "- pdfa (poprzez download as pdf)\n",
    "- jako plik w repozytorium na np. GitHubie, by budować swoje portfolio (wtedy uważaj na wielkość pliku, najlepiej kilka MB, Max 25MB)\n",
    "\n",
    "Najlepiej, by w notebooku było widać wyniki uruchomienia komórek, chyba, że przez nie plik będzie mieć 100+MB wtedy najlepiej Colab lub jakieś przemyślenie co poszło nie tak (zbyt dużo dużych zdjęć wyświetlonych w komórkach).\n",
    "\n",
    "## Co otrzymasz?\n",
    "Informację zwrotną z ewentualnymi sugestiami, komentarzami."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
